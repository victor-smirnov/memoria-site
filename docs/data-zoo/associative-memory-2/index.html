<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://memoria-framework.dev/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://memoria-framework.dev/fonts/vendor/jost/jost-v4-latin-500.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://memoria-framework.dev/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://memoria-framework.dev/fonts/KaTeX_Main-Regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://memoria-framework.dev/fonts/KaTeX_Math-Italic.woff2 type=font/woff2 crossorigin><link rel=stylesheet href=https://memoria-framework.dev/main.936beb930fd98ad42e9ffeb326821156010eee32296e56a34ddbc6be19fe80fa939278f5ca78e22e25b3e3a8808e25f8050913e6a9c92db586b3d82e09e3d179.css integrity="sha512-k2vrkw/ZitQun/6zJoIRVgEO7jIpblajTdvGvhn+gPqTknj1ynjiLiWz46iAjiX4BQkT5qnJLbWGs9guCePReQ==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>Associative Memory (Part 2) - Memoria</title><meta name=description content="In the previous part we saw how LOUDS tree can be used for generic compact and efficient associative associative memory over arbitrary number of dimensions. In this part we will see how LOUDS trees can be used for function approximation and inversion.
Definitions #Let $[0, 1] \in R$ is the domain and range we are operating on. $D$ is a number of dimensions of our space, and for the sake of visualizability, $D = 2$."><link rel=canonical href=https://memoria-framework.dev/docs/data-zoo/associative-memory-2/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Associative Memory (Part 2)"><meta property="og:description" content="In the previous part we saw how LOUDS tree can be used for generic compact and efficient associative associative memory over arbitrary number of dimensions. In this part we will see how LOUDS trees can be used for function approximation and inversion.
Definitions #Let $[0, 1] \in R$ is the domain and range we are operating on. $D$ is a number of dimensions of our space, and for the sake of visualizability, $D = 2$."><meta property="og:url" content="https://memoria-framework.dev/docs/data-zoo/associative-memory-2/"><meta property="og:site_name" content="Memoria"><meta property="article:published_time" content="2021-10-28T02:07:01-04:00"><meta property="article:modified_time" content="2021-10-28T02:07:01-04:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content><meta name=twitter:creator content><meta name=twitter:title content="Associative Memory (Part 2)"><meta name=twitter:description content><meta name=twitter:card content="summary"><meta name=twitter:image:alt content="Associative Memory (Part 2)"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://memoria-framework.dev/#/schema/person/1","name":"Memoria","url":"https://memoria-framework.dev/","sameAs":[],"image":{"@type":"ImageObject","@id":"https://memoria-framework.dev/#/schema/image/1","url":"https://memoria-framework.dev/\u003cnil\u003e","width":null,"height":null,"caption":"Memoria"}},{"@type":"WebSite","@id":"https://memoria-framework.dev/#/schema/website/1","url":"https://memoria-framework.dev/","name":"Memoria","description":"","publisher":{"@id":"https://memoria-framework.dev/#/schema/person/1"}},{"@type":"WebPage","@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/","url":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/","name":"Associative Memory (Part 2)","description":"","isPartOf":{"@id":"https://memoria-framework.dev/#/schema/website/1"},"about":{"@id":"https://memoria-framework.dev/#/schema/person/1"},"datePublished":"2021-10-28T02:07:01CET","dateModified":"2021-10-28T02:07:01CET","breadcrumb":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://memoria-framework.dev/docs/data-zoo/associative-memory-2/"]}]},{"@type":"BreadcrumbList","@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://memoria-framework.dev/","url":"https://memoria-framework.dev/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://memoria-framework.dev/docs/","url":"https://memoria-framework.dev/docs/","name":"Docs"}},{"@type":"ListItem","position":3,"item":{"@type":"WebPage","@id":"https://memoria-framework.dev/docs/data-zoo/","url":"https://memoria-framework.dev/docs/data-zoo/","name":"Data Zoo"}},{"@type":"ListItem","position":4,"item":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Article","@id":"https://memoria-framework.dev/#/schema/article/1","headline":"Associative Memory (Part 2)","description":"","isPartOf":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/"},"mainEntityOfPage":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/"},"datePublished":"2021-10-28T02:07:01CET","dateModified":"2021-10-28T02:07:01CET","author":{"@id":"https://memoria-framework.dev/#/schema/person/2"},"publisher":{"@id":"https://memoria-framework.dev/#/schema/person/1"},"image":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/#/schema/image/2"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://memoria-framework.dev/#/schema/person/2","name":"Victor Smirnov","sameAs":[]}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/#/schema/image/2","url":null,"contentUrl":null,"caption":"Associative Memory (Part 2)"}]}]}</script><meta name=theme-color content="#fff"><link rel=icon href=https://memoria-framework.dev/favicon.ico sizes=any><link rel=apple-touch-icon sizes=180x180 href=https://memoria-framework.dev/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://memoria-framework.dev/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://memoria-framework.dev/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://memoria-framework.dev/site.webmanifest></head><body class="docs single"><div class=header-bar></div><header class="navbar navbar-expand-lg navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-lg-nowrap" aria-label="Main navigation"><a class="navbar-brand order-0" href=/ aria-label=Memoria>Memoria</a>
<button class="btn btn-menu order-2 d-block d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-end border-0 py-lg-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-lg-none"></div><div class="offcanvas-header d-lg-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=/>Memoria</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body p-4 p-lg-0"><ul class="nav flex-column flex-lg-row align-items-lg-center mt-2 mt-lg-0 ms-lg-2 me-lg-auto"><li class=nav-item><a class="nav-link ps-0 py-1 active" href=/docs/overview/introduction/>Docs</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/tutorial/quick-start>Tutorial</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/api/overview/>API</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/python/overview/>Python</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/subprojects/overview/>Subprojects</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/victor-smirnov/memoria/issues>Issues</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/victor-smirnov/memoria/discussions>Discussions</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/victor-smirnov/memoria/wiki>Releases</a></li></ul><hr class="text-black-50 my-4 d-lg-none"><form class="doks-search position-relative flex-grow-1 ms-lg-auto me-lg-2"><input id=search class="form-control is-search" type=search placeholder aria-label autocomplete=off><div id=suggestions class="shadow bg-white rounded d-none"></div></form><hr class="text-black-50 my-4 d-lg-none"><ul class="nav flex-column flex-lg-row"><li class=nav-item><a class="nav-link social-link" href=https://github.com/victor-smirnov/memoria><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-lg-none">GitHub</small></a></li></ul></div></div></nav></header><div class=container-xxl><aside class=doks-sidebar><nav id=doks-docs-nav class="collapse d-lg-none" aria-label="Tertiary navigation"><h3 class="h6 text-uppercase mb-2">Overview</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/overview/introduction/>Introduction to Memoria</a></li><li><a class=docs-link href=/docs/overview/definitions/>Basic Definitions</a></li><li><a class=docs-link href=/docs/overview/whyc++/>Why C++</a></li><li><a class=docs-link href=/docs/overview/hardware-accel/>Hardware Acceleration in Memoria</a></li><li><a class=docs-link href=/docs/overview/qt_creator_instructions/>QT Creator Instructions</a></li><li><a class=docs-link href=/docs/overview/faq/>FAQ</a></li></ul><h3 class="h6 text-uppercase mb-2">Data Zoo</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/data-zoo/overview/>Core Data Structures -- Overview</a></li><li><a class=docs-link href=/docs/data-zoo/partial-sum-tree/>Partial Sums Tree</a></li><li><a class=docs-link href=/docs/data-zoo/searchable-seq/>Searchable Sequence</a></li><li><a class=docs-link href=/docs/data-zoo/compressed-symbol-seq/>Compressed Symbol Sequence</a></li><li><a class=docs-link href=/docs/data-zoo/hierarchical-table/>Hierarchical Table</a></li><li><a class=docs-link href=/docs/data-zoo/louds-tree/>Level Order Unary Degree Sequence (LOUDS)</a></li><li><a class=docs-link href=/docs/data-zoo/wavelet-tree/>Multiary Wavelet Trees</a></li><li><a class=docs-link href=/docs/data-zoo/mutistream-tree/>Mutistream Balanced Tree</a></li><li><a class=docs-link href=/docs/data-zoo/packed-allocator/>Packed Allocator</a></li><li><a class=docs-link href=/docs/data-zoo/associative-memory-1/>Associative Memory (Part 1)</a></li><li><a class="docs-link active" href=/docs/data-zoo/associative-memory-2/>Associative Memory (Part 2)</a></li></ul><h3 class="h6 text-uppercase mb-2">Storage Engines</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/storage/overview/>Storage Engines Overview</a></li><li><a class=docs-link href=/docs/storage/memory-store/>Memory Store</a></li><li><a class=docs-link href=/docs/storage/swmr-store/>SWMR Store</a></li><li><a class=docs-link href=/docs/storage/overlay-store/>Overlay Store</a></li></ul><h3 class="h6 text-uppercase mb-2">Runtime Environment</h3><h3 class="h6 text-uppercase mb-2">Linked Data & SDN</h3><h3 class="h6 text-uppercase mb-2">Digital Philosophy</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/d-phil/intro/>Philosophy of Memoria - Intro</a></li><li><a class=docs-link href=/docs/d-phil/ai/>Memoria and Artificial Intelligence</a></li></ul><h3 class="h6 text-uppercase mb-2">Memoria Build Tool</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/mbt/overview/>MBT Overview</a></li></ul><h3 class="h6 text-uppercase mb-2">Testing Framework</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/tests/overview/>Tests -- Overview</a></li></ul><h3 class="h6 text-uppercase mb-2">Datascope</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/datascope/overview/>Datascope Overview</a></li></ul><h3 class="h6 text-uppercase mb-2">Misc</h3></nav></aside></div><div class="wrap container-xxl" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar docs-sidebar-top d-none d-lg-block"><nav class=docs-links aria-label="Main navigation"><h3 class="h6 text-uppercase mb-2">Overview</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/overview/introduction/>Introduction to Memoria</a></li><li><a class=docs-link href=/docs/overview/definitions/>Basic Definitions</a></li><li><a class=docs-link href=/docs/overview/whyc++/>Why C++</a></li><li><a class=docs-link href=/docs/overview/hardware-accel/>Hardware Acceleration in Memoria</a></li><li><a class=docs-link href=/docs/overview/qt_creator_instructions/>QT Creator Instructions</a></li><li><a class=docs-link href=/docs/overview/faq/>FAQ</a></li></ul><h3 class="h6 text-uppercase mb-2">Data Zoo</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/data-zoo/overview/>Core Data Structures -- Overview</a></li><li><a class=docs-link href=/docs/data-zoo/partial-sum-tree/>Partial Sums Tree</a></li><li><a class=docs-link href=/docs/data-zoo/searchable-seq/>Searchable Sequence</a></li><li><a class=docs-link href=/docs/data-zoo/compressed-symbol-seq/>Compressed Symbol Sequence</a></li><li><a class=docs-link href=/docs/data-zoo/hierarchical-table/>Hierarchical Table</a></li><li><a class=docs-link href=/docs/data-zoo/louds-tree/>Level Order Unary Degree Sequence (LOUDS)</a></li><li><a class=docs-link href=/docs/data-zoo/wavelet-tree/>Multiary Wavelet Trees</a></li><li><a class=docs-link href=/docs/data-zoo/mutistream-tree/>Mutistream Balanced Tree</a></li><li><a class=docs-link href=/docs/data-zoo/packed-allocator/>Packed Allocator</a></li><li><a class=docs-link href=/docs/data-zoo/associative-memory-1/>Associative Memory (Part 1)</a></li><li><a class="docs-link active" href=/docs/data-zoo/associative-memory-2/>Associative Memory (Part 2)</a></li></ul><h3 class="h6 text-uppercase mb-2">Storage Engines</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/storage/overview/>Storage Engines Overview</a></li><li><a class=docs-link href=/docs/storage/memory-store/>Memory Store</a></li><li><a class=docs-link href=/docs/storage/swmr-store/>SWMR Store</a></li><li><a class=docs-link href=/docs/storage/overlay-store/>Overlay Store</a></li></ul><h3 class="h6 text-uppercase mb-2">Runtime Environment</h3><h3 class="h6 text-uppercase mb-2">Linked Data & SDN</h3><h3 class="h6 text-uppercase mb-2">Digital Philosophy</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/d-phil/intro/>Philosophy of Memoria - Intro</a></li><li><a class=docs-link href=/docs/d-phil/ai/>Memoria and Artificial Intelligence</a></li></ul><h3 class="h6 text-uppercase mb-2">Memoria Build Tool</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/mbt/overview/>MBT Overview</a></li></ul><h3 class="h6 text-uppercase mb-2">Testing Framework</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/tests/overview/>Tests -- Overview</a></li></ul><h3 class="h6 text-uppercase mb-2">Datascope</h3><ul class=list-unstyled><li><a class=docs-link href=/docs/datascope/overview/>Datascope Overview</a></li></ul><h3 class="h6 text-uppercase mb-2">Misc</h3></nav></div><nav class="docs-toc docs-toc-top d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span></span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#definitions>Definitions</a></li><li><a href=#basic-asymptotic-complexity>Basic Asymptotic Complexity</a></li><li><a href=#functions-approximation-using-quad-trees>Functions Approximation Using Quad Trees</a></li><li><a href=#function-compression>Function Compression</a></li><li><a href=#blessing-of-dimensionality-vs-curse-of-dimensionality>Blessing of Dimensionality vs Curse of Dimensionality</a></li><li><a href=#comparison-with-multi-layer-perceptrons>Comparison with Multi-Layer Perceptrons</a></li><li><a href=#hardware-acceleration>Hardware Acceleration</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3></h3><nav id=TableOfContents><ul><li><a href=#definitions>Definitions</a></li><li><a href=#basic-asymptotic-complexity>Basic Asymptotic Complexity</a></li><li><a href=#functions-approximation-using-quad-trees>Functions Approximation Using Quad Trees</a></li><li><a href=#function-compression>Function Compression</a></li><li><a href=#blessing-of-dimensionality-vs-curse-of-dimensionality>Blessing of Dimensionality vs Curse of Dimensionality</a></li><li><a href=#comparison-with-multi-layer-perceptrons>Comparison with Multi-Layer Perceptrons</a></li><li><a href=#hardware-acceleration>Hardware Acceleration</a></li></ul></nav></div></nav><main class="docs-content col-lg-11 col-xl"><h1>Associative Memory (Part 2)</h1><p class=lead></p><nav class=d-xl-none aria-label="Quaternary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span></span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#definitions>Definitions</a></li><li><a href=#basic-asymptotic-complexity>Basic Asymptotic Complexity</a></li><li><a href=#functions-approximation-using-quad-trees>Functions Approximation Using Quad Trees</a></li><li><a href=#function-compression>Function Compression</a></li><li><a href=#blessing-of-dimensionality-vs-curse-of-dimensionality>Blessing of Dimensionality vs Curse of Dimensionality</a></li><li><a href=#comparison-with-multi-layer-perceptrons>Comparison with Multi-Layer Perceptrons</a></li><li><a href=#hardware-acceleration>Hardware Acceleration</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3></h3><nav id=TableOfContents><ul><li><a href=#definitions>Definitions</a></li><li><a href=#basic-asymptotic-complexity>Basic Asymptotic Complexity</a></li><li><a href=#functions-approximation-using-quad-trees>Functions Approximation Using Quad Trees</a></li><li><a href=#function-compression>Function Compression</a></li><li><a href=#blessing-of-dimensionality-vs-curse-of-dimensionality>Blessing of Dimensionality vs Curse of Dimensionality</a></li><li><a href=#comparison-with-multi-layer-perceptrons>Comparison with Multi-Layer Perceptrons</a></li><li><a href=#hardware-acceleration>Hardware Acceleration</a></li></ul></nav></div></nav><p>In the <a href=/docs/data-zoo/associative-memory-1>previous part</a> we saw how LOUDS tree can be used for generic compact and efficient associative associative memory over arbitrary number of dimensions. In this part we will see how LOUDS trees can be used for function approximation and inversion.</p><h2 id=definitions>Definitions <a href=#definitions class=anchor aria-hidden=true>#</a></h2><p>Let $[0, 1] \in R$ is the domain and range we are operating on. $D$ is a number of dimensions of our space, and for the sake of visualizability, $D = 2$.</p><p>Let $\vec{X}$ is a vector encoding a point in $[0, 1]^D$, $\vec{X} = &lt;x_0, x_1, &mldr;, x_{D-1}>$. Let $str(x [, h])$ is a function converting a real number from $[0, 1]$ into a binary string by taking a binary representation of a real number to a form like &ldquo;$0.0010111010&mldr;$&rdquo;, and removing leading &ldquo;$0.$&rdquo; and trailing &ldquo;$0&mldr;$&rdquo;. so, $str(0.181640625) = 001011101$. If $h$ argument is specified for $str(\cdot, \cdot)$, then resulting string is trimmed to $h$ binary digits, if it&rsquo;s longer than that.</p><p>Let $len(x)$ is a number of digits in the result of $str(x)$. Note that $len(\pi / 10) = \infty$, so irrational numbers are literally infinite in this notation. Let $H$ is a maximal <em>depth</em> of data, and there is some <em>implicitly assumed</em> arbitrary value for $h$, like 32 or 64, or even 128. So we can work with <em>approximations</em> of irrational and transcendent numbers, or with long rational numbers in a same way and without loss of generality.</p><p>Let $len(\vec{X}) = max_{\substack{i \in \lbrace 0,&mldr;,D-1 \rbrace }}(len(x_i))$.</p><p>Let $str(\vec{X}) = (str(x_0),&mldr;, str(x_{D-1}))$ is a string representation (a tuple) of $\vec{X}$. And let we assume, elements of the tuple are implicitly extended with &lsquo;$0$&rsquo; from the right, if their length is less than $len(\vec{X})$. In other words, all elements (binary string) of a tuple are implicitly of the same length.</p><p>Let $str(\lbrace \vec{X_0}, \vec{X_1}, &mldr; \rbrace) = \lbrace str(\vec{X_0}), str(\vec{X_1}), &mldr; \rbrace$. String representation of set of vectors is a set of string representation of individual vectors.</p><p>Let $M(\vec{X}) = M(str(\vec{X}))$ is a <a href=/docs/data-zoo/associative-memory-1/#multiscale-decomposition>multiscale transformation</a> of binary string representation of $\vec{X}$. Informally, to compute $M(\vec{X})$ we need to take all strings from its string representation (the tuple of binary strings) and produce another string of length $len(\vec{X}) D$ by concatenating interleaved bits from each binary string in the tuple.</p><p>Example. Let $H = 3$ and $D = 2$. $\vec{X} = &lt;0.625, 0.25>$, $str(\vec{X}) = (101, 01)$ and $M(\vec{X}) = 10|01|10$. Note that signs $|$ are added to separate $H$ <em>path elements</em> in the recording, they are here for the sake of visualization and are not a part of the representation. The string $10|01|10$ is also called <em>path expression</em> because it&rsquo;s a unique path in the multidimensional space decomposition <em>encoding</em> the position of $\vec{X}$ in this decomposition. Visually:</p><figure><img src=multiscale1.svg width=100%></figure><p>Note that the order in which <em>path elements</em> of a path expression enumerate the volume is <a href=https://en.wikipedia.org/wiki/Z-order_curve>Z-order</a>.</p><p>Given a <em>set</em> of $D$-dimensional vectors $\lbrace \vec{X} \rbrace$, it&rsquo;s multiscale transformation can be represented as a $D$-dimensional <a href=https://en.wikipedia.org/wiki/Quadtree>Quad Tree</a>. Such quad tree can be represented with a <a href=/docs/data-zoo/louds-tree/#cardinal-trees>cardinal LOUDS tree</a> of degree $2^D$. Here, implicit parameter $H$ is a <em>maximal height</em> of the Quad Tree.</p><h2 id=basic-asymptotic-complexity>Basic Asymptotic Complexity <a href=#basic-asymptotic-complexity class=anchor aria-hidden=true>#</a></h2><p>Given that $N = |\lbrace \vec{X} \rbrace|$, and given that LOUDS tree is dynamic (represented internally as a b-tree), the following complexity estimations apply:</p><ol><li><strong>Insertion and deletion</strong> of a point is $O(H log(N))$. Update is semantically not defined because it&rsquo;s a <em>set</em>. Batch updates in Z-order are $O(H (log(N) + B))$, where $B$ is a batch size. Otherwise can be slightly worse, up to $O(H log(N) B)$ in the worst case.</li><li><strong>Point lookup</strong> (membership query) is $O(D H log(N))$.</li><li><strong>Range and projection</strong> queries are $O(D H log(N) + M)$ <em>on average</em>, where $M$ is a recall size (number of vectors matching the query). In worst case tree traversal degrades to the linear scan of the entire set of vectors.</li><li>The data structure is <strong>space efficient</strong>. 2 bits per LOUDS tree node + <em>compressed bitmap</em> of cardinal labels. For most usage scenarios, space complexity will be within <strong>2x the raw bit size</strong> of $str(\lbrace \vec{X} \rbrace)$.</li></ol><h2 id=functions-approximation-using-quad-trees>Functions Approximation Using Quad Trees <a href=#functions-approximation-using-quad-trees class=anchor aria-hidden=true>#</a></h2><p>Let we have some function $y = f(x)$, and we also have the graph of this function on $[0, 1]^2$. If function $f(\cdot)$ is elementary, or we have another way to compute it, it&rsquo;s computable (for us). What if we have $f(\cdot)$, but we want to compute inverse function: $x = f^{-1}(y)$? With compact quad trees we can <em>approximate</em> both functions out of the same <em>function graph</em> using compact quad trees:</p><figure><img src=function.svg width=100%></figure><p>Here the tree has four layers shown upside down (drawing more detailed layers above less detailed ones). And if we want to compute $f(a)$, where $str(a) = a_3a_2a_1a_0$, the path expression will be $a_3x|a_2x|a_1x|a_0x$, where $x$ here is a <em>placeholder sign</em>. Now we need to traverse the tree as it defined in <a href=/docs/data-zoo/associative-memory-1/#multiscale-decomposition>previous part</a>. If there is a point for $a$ of a function graph, it will be found in a logarithmic expected time. The path expression for $f^{-1}(b)$ will be $b_3x|b_2x|b_1x|b_0x$.</p><p>Note that compressed cardinal LOUDS tree will use less than 4 bits (+ some % of auxiliary data) <em>per square</em> on the graph above. Sol, looking into this graph we already can say something specific about what will be the cost of approximation, depending on required precision (maximal $H$).</p><h2 id=function-compression>Function Compression <a href=#function-compression class=anchor aria-hidden=true>#</a></h2><p>Let we have a function that checks if some point is inside some ellipse:</p>$$
y = f(x_1, x_2): \begin{cases}
1 &\text{if } (x_1, x_2) \text{ is inside the the ellipse,} \\
0 &\text{if it's outside.} 
\end{cases}
$$<p>This function defines some <em>area</em> on the graph. Let $N$ is the number of &ldquo;pixels&rdquo; we need to define the function $f(x,y)$ on a graph. Then, using compressed quad trees, we can do it with ${O(\sqrt{N})}$ bits <em>on average</em> for 2D space :</p><figure><img src=region.svg></figure><p>The square root here is because we need &ldquo;detailed&rdquo; only for the border of the area, while &ldquo;in-lands&rdquo; needs much lower resolution.</p><h2 id=blessing-of-dimensionality-vs-curse-of-dimensionality>Blessing of Dimensionality vs Curse of Dimensionality <a href=#blessing-of-dimensionality-vs-curse-of-dimensionality class=anchor aria-hidden=true>#</a></h2><p>Let we have 2D space and we have a tree encoding the following structure:</p><figure><img src=corners.svg></figure><p>There are four points in each corner of the coordinate plane. As it can be obvious from the picture, each new level of the tree will add four new bits for just for cardinal labels (not including LOUDS tree itself): three &lsquo;0&rsquo; and one &lsquo;1&rsquo; (in the corresponding corners). Now if we go to higher dimensions, for 3D we will have 8 new bits, for 8D &ndash; 256 new bits and for 32D &ndash; $2^32$ bits. This is <strong>Curse of Dimensionality</strong> (CoD) for spatial data structures: volume grows exponentially with dimensions, so linear sizes &ndash; too.</p><p>Nevertheless, with higher dimensions, the volume is getting exponentially sparser, so we can use data compression techniques like RLE encoding to represent long sparse bitmaps for cardinal labels. This is <strong>Blessing of Dimensionality</strong> (BoD). For <em>compressed</em> LOUDS cardinal trees, the example above will require $O(D)$ bits per quadrant per tree layer for $D$-dimensional Quad Tree.</p><p>So, the the whole idea of compression in this context is implicit (or in-place) <strong>Dimensionality Reduction</strong>. Compressed data structure don&rsquo;t degrade so fast as their uncompressed analogs, yet maintain the same <em>logical API</em>. Nevertheless, data compression is not the final cure for CoD, because practical compression itself is not that powerful, especially in the case of using RLE for bitmap compression. So, in each practical case high-dimensional tree can become &ldquo;unstable&rdquo; and &ldquo;explode&rdquo; in size. Fortunately, such highly-dimensional data ($D > 16$) is rarely makes sense to work with directly (without prior dimensionality reduction).</p><p>For example, for $D=8$ exponential effects in space are still pretty moderate (256-degree cardinal tree), yet 8 dimensions is already a good approximation of real objects in symbolic methods. High-dimensional structures are effectively <em>black boxes</em> for us, because our visual intuitions about properties of objects don&rsquo;t work in <a href=https://www.math.wustl.edu/~feres/highdim>high dimensions</a>. Like, volume of cube is concentrating in it&rsquo;s corners (because there is an exponentional number of corners). Or the volume of sphere is concentrating near its surface, and many more&mldr; Making decisions in high dimensions suffer from noise in data and machine rounding, because points tend to be very close to each other. And, of course, computing Euclidian distance does not make (much) sense.</p><h2 id=comparison-with-multi-layer-perceptrons>Comparison with Multi-Layer Perceptrons <a href=#comparison-with-multi-layer-perceptrons class=anchor aria-hidden=true>#</a></h2><p>Neural networks has been known to be a pretty good function approximators, especially for multi-dimensional cases. Let&rsquo;s check how compressed spatial tree can be compared with multi-layer perceptrons (MLP). This type of artificial neural networks is by no means the best example of ANNs, yet it&rsquo;s a pretty ideomatic member of this family.</p><p>In the core of MLP is the idea of <em>linear separability</em>. In a bacis case, there are two regions of multidimensional space that can&rsquo;t be separated by a hyperplane from each other. MLP has multiple ($K$) layers, where first $K-1$ layers perform specific space transformations using linear (weights) and non-linear (thresholds) operators in such way that $K$-th layer can perform the linear separation:</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/k-Ann9GIbP4 style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p>So, this condition is simplified of the picture below. Here, we have two classes (<em>red</em> and <em>green</em> dots) with complex non-linear boundary between those classes. After transforming the space towards linear separation of those classes and making inverse transformation, the initial hyperplane (here, a line) is broken in many places:</p><figure><img src=classifier.svg></figure><p>What is important, is that each such like break is an inverse transformation of the original hyperplane. Those transformations has to be described, and description will take some space. So we can speak about the <strong>descriptional (Kolmogorov) complexity of the decision boundary</strong>. Or, in the other way, <em>how many neurons (parameters) we need to encode the decision boundary</em>?</p><p>From Algorithmic Information Theory it&rsquo;s known that arbitrary string $s$, drawn from a uniform distribution, will be <em>incompressible</em> with high probability, or $K(s) \to |s|$. In other words, most mathematically possible objects are <em>random</em>-looking, we hardly can find and exploit any structure in them.</p><p>Returning back to MLP, it&rsquo;s expected that in &ldquo;generic case&rdquo; decision boundaries will be <em>complex</em>: the line between classes will have many breaks, so, may transformations will be needed to describe it with required precision (and this is even not taking CoD into account).</p><p>Describing decision boundaries (DB) with compressed spatial trees may look like a bad idea from the first glance. MLPs encode DB with superpositions of elementary functions (hyperplanes and non-linear units). Quad Trees do it with hyper-cubes, and it&rsquo;s obvious that we may need a lot of hyper-cubes in place of just one arbitrary hyper-plane. If it&rsquo;s the case, we say that hyper-planes <em>generalize</em> DB <em>much better</em> than hyper-cubes:</p><figure><img src=classifier-tree.svg></figure><p>But it should hardly be a surprise, if in a real life case it will be find out that descriptions or the network and the corresponding tree are roughly the same.</p><p>So, Neural Networks may generalize much better in some cases than compressed quad trees and perform better in very high dimensional spaces (they suffer less from CoD because of better generalization), but trees have the following benefits:</p><ol><li>If computational complexity of MLP is $\Omega(W)$ (a lot of large matrix multiplications), where $W$ is number of parameters, complexity of inference in the quad tree is <em>roughly</em> from $O(log(N))$, where $N$ is number of bits of information in the tree. So trees may be much faster than networks <em>on average</em>.</li><li>Quad Trees are dynamic. Neural Networks require retraining in case of updates, at the same time adding (or removing) an element to the tree is $O(log(N))$ <em>worst case</em>. It may be vital for may applications operating on-line, like robotics.</li><li>Quad Trees support &ldquo;inverse inference&rdquo; mode, when we can specify classes (outputs) and see</li></ol><p>So, compressed quad trees may be much better for complex dynamic domains with tight decision boundaries with moderate number of dimensions (8-24). It&rsquo;s not that clear yet how trees will perform in real life applications. Memoria is providing (1) <em>experimental</em> compressed dynamic cardinal LOUDS tree for low dimensional spaces (2 - 64).</p><p>(1) Not yet ready at the time of writing.</p><h2 id=hardware-acceleration>Hardware Acceleration <a href=#hardware-acceleration class=anchor aria-hidden=true>#</a></h2><p>The main point of hardware acceleration of compressed Quad Trees is that inference may be really cheap (on average). It&rsquo;s just a bunch of memory lookups (it&rsquo;s a <em>memory-bound</em> problem). Matrix multipliers, from other size, are also pretty energy efficient. Nevertheless, <em>trees scale better with complexity of decision boundaries</em>.</p><div class="page-footer-meta d-flex flex-column flex-md-row justify-content-between"></div><div class="docs-navigation d-flex justify-content-between"><a href=/docs/data-zoo/associative-memory-1/><div class="card my-1"><div class="card-body py-2">&larr; Associative Memory (Part 1)</div></div></a><a class=ms-auto href=/docs/storage/overview/><div class="card my-1"><div class="card-body py-2">Storage Engines Overview &rarr;</div></div></a></div></main></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Powered by <a href=https://www.github.com/>Github</a>, <a href=https://gohugo.io/>Hugo</a>, and <a href=https://getdoks.org/>Doks</a></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline><li class=list-inline-item><a href=/privacy-policy/>Privacy</a></li></ul></div></div></div></footer><script src=/js/bootstrap.min.f06fe6dc0efc9ee1e806021a0c338278256ecf163b547e8e8769fe60b0a1c0d505782852616ca4e1ff6a719eb8fc954e1d26031b8ab3ca71fb9d9998081b319e.js integrity="sha512-8G/m3A78nuHoBgIaDDOCeCVuzxY7VH6Oh2n+YLChwNUFeChSYWyk4f9qcZ64/JVOHSYDG4qzynH7nZmYCBsxng==" crossorigin=anonymous defer></script>
<script src=/js/highlight.min.349dda7f776056c3f39bc8ccb2eeab63bafd33d052a7266441e0912a4ad60fe0932e116b570cf3b263f7b944035ea6076fb02ee3b541df9fa4a48327b3b2314a.js integrity="sha512-NJ3af3dgVsPzm8jMsu6rY7r9M9BSpyZkQeCRKkrWD+CTLhFrVwzzsmP3uUQDXqYHb7Au47VB35+kpIMns7IxSg==" crossorigin=anonymous defer></script>
<script src=/js/vendor/katex/dist/katex.min.8370e08d29f784ff7c9a902e9acd0e13dbcc29df754e3b6169e0243fddd6efb28a8c3f22d1f82cb26e83f1bb2bf9f5923c696f7dad0e219d8617071e5b45ee15.js integrity="sha512-g3DgjSn3hP98mpAums0OE9vMKd91TjthaeAkP93W77KKjD8i0fgssm6D8bsr+fWSPGlvfa0OIZ2GFwceW0XuFQ==" crossorigin=anonymous defer></script>
<script src=/js/vendor/katex/dist/contrib/auto-render.min.17afcd53ae964f755803834d912cea7b9c8581cd7ab706ddf37fc95ae96365dd6e45f2083d19b63ead2d842388f769d174b4866fff4ddefb85bcbb7a4bba8434.js integrity="sha512-F6/NU66WT3VYA4NNkSzqe5yFgc16twbd83/JWuljZd1uRfIIPRm2Pq0thCOI92nRdLSGb/9N3vuFvLt6S7qENA==" crossorigin=anonymous defer></script>
<script src=/main.min.f4fc9672b82291a008c0e098e13b1cf76efef8389cf4ecfacd957f72a374aac24f8fcd030f4982efbf7ba73dbc434fa95bfa2ae5f78d156d7c269f97c9ef020d.js integrity="sha512-9PyWcrgikaAIwOCY4Tsc927++Dic9Oz6zZV/cqN0qsJPj80DD0mC7797pz28Q0+pW/oq5feNFW18Jp+Xye8CDQ==" crossorigin=anonymous defer></script>
<script src=https://memoria-framework.dev/index.min.58fe3aacc82c707b37a3645ba51a94a2d1400a153b95e2890fb5dda3bb79df0176ae8074d0e017edec4767df990ece151ff81ca58a86e292846beff6d66b9162.js integrity="sha512-WP46rMgscHs3o2RbpRqUotFAChU7leKJD7Xdo7t53wF2roB00OAX7exHZ9+ZDs4VH/gcpYqG4pKEa+/21muRYg==" crossorigin=anonymous defer></script></body></html>