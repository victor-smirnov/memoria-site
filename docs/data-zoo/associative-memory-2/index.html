<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://memoria-framework.dev/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://memoria-framework.dev/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://memoria-framework.dev/fonts/KaTeX_Main-Regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://memoria-framework.dev/fonts/KaTeX_Math-Italic.woff2 type=font/woff2 crossorigin><link rel=stylesheet href=https://memoria-framework.dev/main.4aee7b9c653a9441aeccbab4bf9a20bb4827ed71a21077328be36d74cbe63081492792ee312478e64d73f5e762a2ad3c04431ecfa8d16da63373639763e86b0c.css integrity="sha512-Su57nGU6lEGuzLq0v5ogu0gn7XGiEHcyi+NtdMvmMIFJJ5LuMSR45k1z9edioq08BEMez6jRbaYzc2OXY+hrDA==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>Associative Memory (Part 2) - Memoria</title><meta name=description content><link rel=canonical href=https://memoria-framework.dev/docs/data-zoo/associative-memory-2/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Associative Memory (Part 2)"><meta property="og:description" content="In the previous part we saw how LOUDS tree can be used for generic compact and efficient associative associative memory over arbitrary number of dimensions. In this part we will see how LOUDS trees can be used for function approximation and inversion.
Definitions Let $[0, 1] \in R$ is the domain and range we are operating on. $D$ is a number of dimensions of our space, and for the sake of visualizability, $D = 2$."><meta property="og:url" content="https://memoria-framework.dev/docs/data-zoo/associative-memory-2/"><meta property="og:site_name" content="Memoria"><meta property="article:published_time" content="2021-10-28T02:07:01-04:00"><meta property="article:modified_time" content="2021-10-28T02:07:01-04:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content><meta name=twitter:creator content><meta name=twitter:title content="Associative Memory (Part 2)"><meta name=twitter:description content><meta name=twitter:card content="summary"><meta name=twitter:image:alt content="Associative Memory (Part 2)"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://memoria-framework.dev/#/schema/person/1","name":"Memoria","url":"https://memoria-framework.dev/","sameAs":[],"image":{"@type":"ImageObject","@id":"https://memoria-framework.dev/#/schema/image/1","url":"https://memoria-framework.dev/\u003cnil\u003e","width":null,"height":null,"caption":"Memoria"}},{"@type":"WebSite","@id":"https://memoria-framework.dev/#/schema/website/1","url":"https://memoria-framework.dev/","name":"Memoria","description":"","publisher":{"@id":"https://memoria-framework.dev/#/schema/person/1"}},{"@type":"WebPage","@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/","url":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/","name":"Associative Memory (Part 2)","description":"","isPartOf":{"@id":"https://memoria-framework.dev/#/schema/website/1"},"about":{"@id":"https://memoria-framework.dev/#/schema/person/1"},"datePublished":"2021-10-28T02:07:01CET","dateModified":"2021-10-28T02:07:01CET","breadcrumb":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://memoria-framework.dev/docs/data-zoo/associative-memory-2/"]}]},{"@type":"BreadcrumbList","@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://memoria-framework.dev/","url":"https://memoria-framework.dev/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://memoria-framework.dev/docs/","url":"https://memoria-framework.dev/docs/","name":"Docs"}},{"@type":"ListItem","position":3,"item":{"@type":"WebPage","@id":"https://memoria-framework.dev/docs/data-zoo/","url":"https://memoria-framework.dev/docs/data-zoo/","name":"Data Zoo"}},{"@type":"ListItem","position":4,"item":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Article","@id":"https://memoria-framework.dev/#/schema/article/1","headline":"Associative Memory (Part 2)","description":"","isPartOf":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/"},"mainEntityOfPage":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/"},"datePublished":"2021-10-28T02:07:01CET","dateModified":"2021-10-28T02:07:01CET","author":{"@id":"https://memoria-framework.dev/#/schema/person/2"},"publisher":{"@id":"https://memoria-framework.dev/#/schema/person/1"},"image":{"@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/#/schema/image/2"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://memoria-framework.dev/#/schema/person/2","name":"Victor Smirnov","sameAs":[]}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://memoria-framework.dev/docs/data-zoo/associative-memory-2/#/schema/image/2","url":null,"contentUrl":null,"caption":"Associative Memory (Part 2)"}]}]}</script><meta name=theme-color content="#fff"><link rel=apple-touch-icon sizes=180x180 href=https://memoria-framework.dev/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://memoria-framework.dev/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://memoria-framework.dev/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://memoria-framework.dev/site.webmanifest></head><body class="docs single"><div class=header-bar></div><header class="navbar navbar-expand-md navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-md-nowrap" aria-label="Main navigation"><a class="navbar-brand p-0 me-auto" href=/ aria-label=Memoria>Memoria</a>
<button class="btn btn-menu d-block d-md-none order-5" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-start border-0 py-md-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-md-none"></div><div class="offcanvas-header d-md-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=/>Memoria</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body px-4"><h3 class="h6 text-uppercase mb-3 d-md-none">Main</h3><ul class="nav flex-column flex-md-row ms-md-n3"><li class=nav-item><a class="nav-link ps-0 py-1 active" href=/docs/overview/introduction/>Docs</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/subprojects/overview/>Subprojects</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/victor-smirnov/memoria/issues>Issues</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/victor-smirnov/memoria/discussions>Discussions</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/victor-smirnov/memoria/wiki>Releases</a></li></ul><hr class="text-black-50 my-4 d-md-none"><h3 class="h6 text-uppercase mb-3 d-md-none">Socials</h3><ul class="nav flex-column flex-md-row ms-md-auto me-md-n5 pe-md-2"><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/victor-smirnov/memoria><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-md-none">GitHub</small></a></li></ul></div></div></nav></header><nav class="doks-subnavbar py-2 sticky-lg-top" aria-label="Secondary navigation"><div class="container-xxl d-flex align-items-md-center"><form class="doks-search position-relative flex-grow-1 me-auto"><input id=search class="form-control is-search" type=search placeholder="Search docs..." aria-label="Search docs..." autocomplete=off><div id=suggestions class="shadow bg-white rounded d-none"></div></form><button class="btn doks-sidebar-toggle d-lg-none ms-3 order-3 collapsed" type=button data-bs-toggle=collapse data-bs-target=#doks-docs-nav aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle documentation navigation"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></button></div></nav><div class=container-xxl><aside class=doks-sidebar><nav id=doks-docs-nav class="collapse d-lg-none" aria-label="Tertiary navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-overview aria-expanded=false>
Overview</button><div class=collapse id=section-overview><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/docs/overview/introduction/>Introduction to Memoria</a></li><li><a class="docs-link rounded" href=/docs/overview/philosophy/>Philosophy</a></li><li><a class="docs-link rounded" href=/docs/overview/hermes/>Hermes</a></li><li><a class="docs-link rounded" href=/docs/overview/hrpc/>HRPC: Hermes RPC Protocol</a></li><li><a class="docs-link rounded" href=/docs/overview/containers/>Containers</a></li><li><a class="docs-link rounded" href=/docs/overview/storage/>Storage Engines</a></li><li><a class="docs-link rounded" href=/docs/overview/runtime/>Runtime Environments</a></li><li><a class="docs-link rounded" href=/docs/overview/vm/>DSL Engine</a></li><li><a class="docs-link rounded" href=/docs/overview/accel/>Memoria Acceleration Architecture (MAA)</a></li><li><a class="docs-link rounded" href=/docs/overview/mbt/>Memoria Build Tool</a></li><li><a class="docs-link rounded" href=/docs/overview/qt_creator_instructions/>Qt Creator Instructions</a></li><li><a class="docs-link rounded" href=/docs/overview/roadmap/>Project Roadmap</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-datazoo aria-expanded=true>
Data Zoo</button><div class="collapse show" id=section-datazoo><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/docs/data-zoo/overview/>Core Data Structures -- Overview</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/partial-sum-tree/>Partial Sums Tree</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/searchable-seq/>Searchable Sequence</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/compressed-symbol-seq/>Compressed Symbol Sequence</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/hierarchical-containers/>Hierarchical Containers</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/louds-tree/>Level Order Unary Degree Sequence (LOUDS)</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/wavelet-tree/>Multiary Wavelet Trees</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/packed-allocator/>Packed Allocator</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/associative-memory-1/>Associative Memory (Part 1)</a></li><li><a class="docs-link rounded active" href=/docs/data-zoo/associative-memory-2/>Associative Memory (Part 2)</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-apps aria-expanded=false>
Applications</button><div class=collapse id=section-apps><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/docs/applications/aiml/>Hybrid AI</a></li><li><a class="docs-link rounded" href=/docs/applications/storage/>Computational Storage</a></li><li><a class="docs-link rounded" href=/docs/applications/db/>Converged Databases</a></li><li><a class="docs-link rounded" href=/docs/applications/co-design/>HW/SW Co-design</a></li><li><a class="docs-link rounded" href=/docs/applications/eiot/>Embedded and IoT Applications</a></li></ul></div></li></ul></nav></aside></div><div class="wrap container-xxl" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar d-none d-lg-block"><nav class=docs-links aria-label="Main navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-overview aria-expanded=false>
Overview</button><div class=collapse id=section-overview><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/docs/overview/introduction/>Introduction to Memoria</a></li><li><a class="docs-link rounded" href=/docs/overview/philosophy/>Philosophy</a></li><li><a class="docs-link rounded" href=/docs/overview/hermes/>Hermes</a></li><li><a class="docs-link rounded" href=/docs/overview/hrpc/>HRPC: Hermes RPC Protocol</a></li><li><a class="docs-link rounded" href=/docs/overview/containers/>Containers</a></li><li><a class="docs-link rounded" href=/docs/overview/storage/>Storage Engines</a></li><li><a class="docs-link rounded" href=/docs/overview/runtime/>Runtime Environments</a></li><li><a class="docs-link rounded" href=/docs/overview/vm/>DSL Engine</a></li><li><a class="docs-link rounded" href=/docs/overview/accel/>Memoria Acceleration Architecture (MAA)</a></li><li><a class="docs-link rounded" href=/docs/overview/mbt/>Memoria Build Tool</a></li><li><a class="docs-link rounded" href=/docs/overview/qt_creator_instructions/>Qt Creator Instructions</a></li><li><a class="docs-link rounded" href=/docs/overview/roadmap/>Project Roadmap</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-datazoo aria-expanded=true>
Data Zoo</button><div class="collapse show" id=section-datazoo><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/docs/data-zoo/overview/>Core Data Structures -- Overview</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/partial-sum-tree/>Partial Sums Tree</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/searchable-seq/>Searchable Sequence</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/compressed-symbol-seq/>Compressed Symbol Sequence</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/hierarchical-containers/>Hierarchical Containers</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/louds-tree/>Level Order Unary Degree Sequence (LOUDS)</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/wavelet-tree/>Multiary Wavelet Trees</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/packed-allocator/>Packed Allocator</a></li><li><a class="docs-link rounded" href=/docs/data-zoo/associative-memory-1/>Associative Memory (Part 1)</a></li><li><a class="docs-link rounded active" href=/docs/data-zoo/associative-memory-2/>Associative Memory (Part 2)</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-apps aria-expanded=false>
Applications</button><div class=collapse id=section-apps><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/docs/applications/aiml/>Hybrid AI</a></li><li><a class="docs-link rounded" href=/docs/applications/storage/>Computational Storage</a></li><li><a class="docs-link rounded" href=/docs/applications/db/>Converged Databases</a></li><li><a class="docs-link rounded" href=/docs/applications/co-design/>HW/SW Co-design</a></li><li><a class="docs-link rounded" href=/docs/applications/eiot/>Embedded and IoT Applications</a></li></ul></div></li></ul></nav></div><nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=page-links><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#definitions>Definitions</a></li><li><a href=#basic-asymptotic-complexity>Basic Asymptotic Complexity</a></li><li><a href=#functions-approximation-using-quad-trees>Functions Approximation Using Quad Trees</a></li><li><a href=#function-compression>Function Compression</a></li><li><a href=#blessing-of-dimensionality-vs-curse-of-dimensionality>Blessing of Dimensionality vs Curse of Dimensionality</a></li><li><a href=#comparison-with-multi-layer-perceptrons>Comparison with Multi-Layer Perceptrons</a></li><li><a href=#hardware-acceleration>Hardware Acceleration</a></li></ul></nav></div></nav><main class="docs-content col-lg-11 col-xl-9"><h1>Associative Memory (Part 2)</h1><p class=lead></p><nav class=d-xl-none aria-label="Quaternary navigation"><div class=page-links><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#definitions>Definitions</a></li><li><a href=#basic-asymptotic-complexity>Basic Asymptotic Complexity</a></li><li><a href=#functions-approximation-using-quad-trees>Functions Approximation Using Quad Trees</a></li><li><a href=#function-compression>Function Compression</a></li><li><a href=#blessing-of-dimensionality-vs-curse-of-dimensionality>Blessing of Dimensionality vs Curse of Dimensionality</a></li><li><a href=#comparison-with-multi-layer-perceptrons>Comparison with Multi-Layer Perceptrons</a></li><li><a href=#hardware-acceleration>Hardware Acceleration</a></li></ul></nav></div></nav><p>In the <a href=/docs/data-zoo/associative-memory-1>previous part</a> we saw how LOUDS tree can be used for generic compact and efficient associative associative memory over arbitrary number of dimensions. In this part we will see how LOUDS trees can be used for function approximation and inversion.</p><h2 id=definitions>Definitions<a href=#definitions class=anchor aria-hidden=true>#</a></h2><p>Let $[0, 1] \in R$ is the domain and range we are operating on. $D$ is a number of dimensions of our space, and for the sake of visualizability, $D = 2$.</p><p>Let $\vec{X}$ is a vector encoding a point in $[0, 1]^D$, $\vec{X} = &lt;x_0, x_1, &mldr;, x_{D-1}>$. Let $str(x [, h])$ is a function converting a real number from $[0, 1]$ into a binary string by taking a binary representation of a real number to a form like &ldquo;$0.0010111010&mldr;$&rdquo;, and removing leading &ldquo;$0.$&rdquo; and trailing &ldquo;$0&mldr;$&rdquo;. so, $str(0.181640625) = 001011101$. If $h$ argument is specified for $str(\cdot, \cdot)$, then resulting string is trimmed to $h$ binary digits, if it&rsquo;s longer than that.</p><p>Let $len(x)$ is a number of digits in the result of $str(x)$. Note that $len(\pi / 10) = \infty$, so irrational numbers are literally infinite in this notation. Let $H$ is a maximal <em>depth</em> of data, and there is some <em>implicitly assumed</em> arbitrary value for $h$, like 32 or 64, or even 128. So we can work with <em>approximations</em> of irrational and transcendent numbers, or with long rational numbers in a same way and without loss of generality.</p><p>Let $len(\vec{X}) = max_{\substack{i \in \lbrace 0,&mldr;,D-1 \rbrace }}(len(x_i))$.</p><p>Let $str(\vec{X}) = (str(x_0),&mldr;, str(x_{D-1}))$ is a string representation (a tuple) of $\vec{X}$. And let we assume, elements of the tuple are implicitly extended with &lsquo;$0$&rsquo; from the right, if their length is less than $len(\vec{X})$. In other words, all elements (binary string) of a tuple are implicitly of the same length.</p><p>Let $str(\lbrace \vec{X_0}, \vec{X_1}, &mldr; \rbrace) = \lbrace str(\vec{X_0}), str(\vec{X_1}), &mldr; \rbrace$. String representation of set of vectors is a set of string representation of individual vectors.</p><p>Let $M(\vec{X}) = M(str(\vec{X}))$ is a <a href=/docs/data-zoo/associative-memory-1/#multiscale-decomposition>multiscale transformation</a> of binary string representation of $\vec{X}$. Informally, to compute $M(\vec{X})$ we need to take all strings from its string representation (the tuple of binary strings) and produce another string of length $len(\vec{X}) D$ by concatenating interleaved bits from each binary string in the tuple.</p><p>Example. Let $H = 3$ and $D = 2$. $\vec{X} = &lt;0.625, 0.25>$, $str(\vec{X}) = (101, 01)$ and $M(\vec{X}) = 10|01|10$. Note that signs $|$ are added to separate $H$ <em>path elements</em> in the recording, they are here for the sake of visualization and are not a part of the representation. The string $10|01|10$ is also called <em>path expression</em> because it&rsquo;s a unique path in the multidimensional space decomposition <em>encoding</em> the position of $\vec{X}$ in this decomposition. Visually:</p><figure><img src=multiscale1.svg width=100%></figure><p>Note that the order in which <em>path elements</em> of a path expression enumerate the volume is <a href=https://en.wikipedia.org/wiki/Z-order_curve>Z-order</a>.</p><p>Given a <em>set</em> of $D$-dimensional vectors $\lbrace \vec{X} \rbrace$, it&rsquo;s multiscale transformation can be represented as a $D$-dimensional <a href=https://en.wikipedia.org/wiki/Quadtree>Quad Tree</a>. Such quad tree can be represented with a <a href=/docs/data-zoo/louds-tree/#cardinal-trees>cardinal LOUDS tree</a> of degree $2^D$. Here, implicit parameter $H$ is a <em>maximal height</em> of the Quad Tree.</p><h2 id=basic-asymptotic-complexity>Basic Asymptotic Complexity<a href=#basic-asymptotic-complexity class=anchor aria-hidden=true>#</a></h2><p>Given that $N = |\lbrace \vec{X} \rbrace|$, and given that LOUDS tree is dynamic (represented internally as a b-tree), the following complexity estimations apply:</p><ol><li><strong>Insertion and deletion</strong> of a point is $O(H log(N))$. Update is semantically not defined because it&rsquo;s a <em>set</em>. Batch updates in Z-order are $O(H (log(N) + B))$, where $B$ is a batch size. Otherwise can be slightly worse, up to $O(H log(N) B)$ in the worst case.</li><li><strong>Point lookup</strong> (membership query) is $O(D H log(N))$.</li><li><strong>Range and projection</strong> queries are $O(D H log(N) + M)$ <em>on average</em>, where $M$ is a recall size (number of vectors matching the query). In worst case tree traversal degrades to the linear scan of the entire set of vectors.</li><li>The data structure is <strong>space efficient</strong>. 2 bits per LOUDS tree node + <em>compressed bitmap</em> of cardinal labels. For most usage scenarios, space complexity will be within <strong>2x the raw bit size</strong> of $str(\lbrace \vec{X} \rbrace)$.</li></ol><h2 id=functions-approximation-using-quad-trees>Functions Approximation Using Quad Trees<a href=#functions-approximation-using-quad-trees class=anchor aria-hidden=true>#</a></h2><p>Let we have some function $y = f(x)$, and we also have the graph of this function on $[0, 1]^2$. If function $f(\cdot)$ is elementary, or we have another way to compute it, it&rsquo;s computable (for us). What if we have $f(\cdot)$, but we want to compute inverse function: $x = f^{-1}(y)$? With compact quad trees we can <em>approximate</em> both functions out of the same <em>function graph</em> using compact quad trees:</p><figure><img src=function.svg width=100%></figure><p>Here the tree has four layers shown upside down (drawing more detailed layers above less detailed ones). And if we want to compute $f(a)$, where $str(a) = a_3a_2a_1a_0$, the path expression will be $a_3x|a_2x|a_1x|a_0x$, where $x$ here is a <em>placeholder sign</em>. Now we need to traverse the tree as it defined in <a href=/docs/data-zoo/associative-memory-1/#multiscale-decomposition>previous part</a>. If there is a point for $a$ of a function graph, it will be found in a logarithmic expected time. The path expression for $f^{-1}(b)$ will be $b_3x|b_2x|b_1x|b_0x$.</p><p>Note that compressed cardinal LOUDS tree will use less than 4 bits (+ some % of auxiliary data) <em>per square</em> on the graph above. Sol, looking into this graph we already can say something specific about what will be the cost of approximation, depending on required precision (maximal $H$).</p><h2 id=function-compression>Function Compression<a href=#function-compression class=anchor aria-hidden=true>#</a></h2><p>Let we have a function that checks if some point is inside some ellipse:</p>$$
y = f(x_1, x_2): \begin{cases}
1 &\text{if } (x_1, x_2) \text{ is inside the the ellipse,} \\
0 &\text{if it's outside.} 
\end{cases}
$$<p>This function defines some <em>area</em> on the graph. Let $N$ is the number of &ldquo;pixels&rdquo; we need to define the function $f(x,y)$ on a graph. Then, using compressed quad trees, we can do it with ${O(\sqrt{N})}$ bits <em>on average</em> for 2D space :</p><figure><img src=region.svg></figure><p>The square root here is because we need &ldquo;detailed&rdquo; only for the border of the area, while &ldquo;in-lands&rdquo; needs much lower resolution.</p><h2 id=blessing-of-dimensionality-vs-curse-of-dimensionality>Blessing of Dimensionality vs Curse of Dimensionality<a href=#blessing-of-dimensionality-vs-curse-of-dimensionality class=anchor aria-hidden=true>#</a></h2><p>Let we have 2D space and we have a tree encoding the following structure:</p><figure><img src=corners.svg></figure><p>There are four points in each corner of the coordinate plane. As it can be obvious from the picture, each new level of the tree will add four new bits for just for cardinal labels (not including LOUDS tree itself): three &lsquo;0&rsquo; and one &lsquo;1&rsquo; (in the corresponding corners). Now if we go to higher dimensions, for 3D we will have 8 new bits, for 8D &ndash; 256 new bits and for 32D &ndash; $2^32$ bits. This is <strong>Curse of Dimensionality</strong> (CoD) for spatial data structures: volume grows exponentially with dimensions, so linear sizes &ndash; too.</p><p>Nevertheless, with higher dimensions, the volume is getting exponentially sparser, so we can use data compression techniques like RLE encoding to represent long sparse bitmaps for cardinal labels. This is <strong>Blessing of Dimensionality</strong> (BoD). For <em>compressed</em> LOUDS cardinal trees, the example above will require $O(D)$ bits per quadrant per tree layer for $D$-dimensional Quad Tree.</p><p>So, the the whole idea of compression in this context is implicit (or in-place) <strong>Dimensionality Reduction</strong>. Compressed data structure don&rsquo;t degrade so fast as their uncompressed analogs, yet maintain the same <em>logical API</em>. Nevertheless, data compression is not the final cure for CoD, because practical compression itself is not that powerful, especially in the case of using RLE for bitmap compression. So, in each practical case high-dimensional tree can become &ldquo;unstable&rdquo; and &ldquo;explode&rdquo; in size. Fortunately, such highly-dimensional data ($D > 16$) is rarely makes sense to work with directly (without prior dimensionality reduction).</p><p>For example, for $D=8$ exponential effects in space are still pretty moderate (256-degree cardinal tree), yet 8 dimensions is already a good approximation of real objects in symbolic methods. High-dimensional structures are effectively <em>black boxes</em> for us, because our visual intuitions about properties of objects don&rsquo;t work in <a href=https://www.math.wustl.edu/~feres/highdim>high dimensions</a>. Like, volume of cube is concentrating in it&rsquo;s corners (because there is an exponentional number of corners). Or the volume of sphere is concentrating near its surface, and many more&mldr; Making decisions in high dimensions suffer from noise in data and machine rounding, because points tend to be very close to each other. And, of course, computing Euclidian distance does not make (much) sense.</p><h2 id=comparison-with-multi-layer-perceptrons>Comparison with Multi-Layer Perceptrons<a href=#comparison-with-multi-layer-perceptrons class=anchor aria-hidden=true>#</a></h2><p>Neural networks has been known to be a pretty good function approximators, especially for multi-dimensional cases. Let&rsquo;s check how compressed spatial tree can be compared with multi-layer perceptrons (MLP). This type of artificial neural networks is by no means the best example of ANNs, yet it&rsquo;s a pretty ideomatic member of this family.</p><p>In the core of MLP is the idea of <em>linear separability</em>. In a bacis case, there are two regions of multidimensional space that can&rsquo;t be separated by a hyperplane from each other. MLP has multiple ($K$) layers, where first $K-1$ layers perform specific space transformations using linear (weights) and non-linear (thresholds) operators in such way that $K$-th layer can perform the linear separation:</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/k-Ann9GIbP4 style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p>So, this condition is simplified of the picture below. Here, we have two classes (<em>red</em> and <em>green</em> dots) with complex non-linear boundary between those classes. After transforming the space towards linear separation of those classes and making inverse transformation, the initial hyperplane (here, a line) is broken in many places:</p><figure><img src=classifier.svg></figure><p>What is important, is that each such like break is an inverse transformation of the original hyperplane. Those transformations has to be described, and description will take some space. So we can speak about the <strong>descriptional (Kolmogorov) complexity of the decision boundary</strong>. Or, in the other way, <em>how many neurons (parameters) we need to encode the decision boundary</em>?</p><p>From Algorithmic Information Theory it&rsquo;s known that arbitrary string $s$, drawn from a uniform distribution, will be <em>incompressible</em> with high probability, or $K(s) \to |s|$. In other words, most mathematically possible objects are <em>random</em>-looking, we hardly can find and exploit any structure in them.</p><p>Returning back to MLP, it&rsquo;s expected that in &ldquo;generic case&rdquo; decision boundaries will be <em>complex</em>: the line between classes will have many breaks, so, may transformations will be needed to describe it with required precision (and this is even not taking CoD into account).</p><p>Describing decision boundaries (DB) with compressed spatial trees may look like a bad idea from the first glance. MLPs encode DB with superpositions of elementary functions (hyperplanes and non-linear units). Quad Trees do it with hyper-cubes, and it&rsquo;s obvious that we may need a lot of hyper-cubes in place of just one arbitrary hyper-plane. If it&rsquo;s the case, we say that hyper-planes <em>generalize</em> DB <em>much better</em> than hyper-cubes:</p><figure><img src=classifier-tree.svg></figure><p>But it should hardly be a surprise, if in a real life case it will be find out that descriptions or the network and the corresponding tree are roughly the same.</p><p>So, Neural Networks may generalize much better in some cases than compressed quad trees and perform better in very high dimensional spaces (they suffer less from CoD because of better generalization), but trees have the following benefits:</p><ol><li>If computational complexity of MLP is $\Omega(W)$ (a lot of large matrix multiplications), where $W$ is number of parameters, complexity of inference in the quad tree is <em>roughly</em> from $O(log(N))$, where $N$ is number of bits of information in the tree. So trees may be much faster than networks <em>on average</em>.</li><li>Quad Trees are dynamic. Neural Networks require retraining in case of updates, at the same time adding (or removing) an element to the tree is $O(log(N))$ <em>worst case</em>. It may be vital for may applications operating on-line, like robotics.</li><li>Quad Trees support &ldquo;inverse inference&rdquo; mode, when we can specify classes (outputs) and see</li></ol><p>So, compressed quad trees may be much better for complex dynamic domains with tight decision boundaries with moderate number of dimensions (8-24). It&rsquo;s not that clear yet how trees will perform in real life applications. Memoria is providing (1) <em>experimental</em> compressed dynamic cardinal LOUDS tree for low dimensional spaces (2 - 64).</p><p>(1) Not yet ready at the time of writing.</p><h2 id=hardware-acceleration>Hardware Acceleration<a href=#hardware-acceleration class=anchor aria-hidden=true>#</a></h2><p>The main point of hardware acceleration of compressed Quad Trees is that inference may be really cheap (on average). It&rsquo;s just a bunch of memory lookups (it&rsquo;s a <em>memory-bound</em> problem). Matrix multipliers, from other size, are also pretty energy efficient. Nevertheless, <em>trees scale better with complexity of decision boundaries</em>.</p><div class="docs-navigation d-flex justify-content-between"><a href=/docs/data-zoo/associative-memory-1/><div class="card my-1"><div class="card-body py-2">&larr; Associative Memory (Part 1)</div></div></a><a class=ms-auto href=/docs/applications/aiml/><div class="card my-1"><div class="card-body py-2">Hybrid AI &rarr;</div></div></a></div></main></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Powered by <a href=https://www.github.com/>Github</a>, <a href=https://gohugo.io/>Hugo</a>, and <a href=https://getdoks.org/>Doks</a></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline><li class=list-inline-item><a href=/privacy-policy/>Privacy</a></li></ul></div></div></div></footer><script src=/js/bootstrap.min.73ca27033146a505b6a0f66b79d99f613a18e778bc9606fd223476d0ebf0fc10508b0d4f5c448b0a946fa1d71fbeffaae9732adc0c2890e61c449217fd6ee1c0.js integrity="sha512-c8onAzFGpQW2oPZredmfYToY53i8lgb9IjR20Ovw/BBQiw1PXESLCpRvodcfvv+q6XMq3AwokOYcRJIX/W7hwA==" crossorigin=anonymous defer></script>
<script src=/js/highlight.min.c5b6bb65307e087bfc3dd5a73cf000f3dc6a8b665db8c3fcbd62a3368e2f82ee494fd1ff5f025a09216cf6390bac7565c5469c6958caac1b9d09c85ba0adfefc.js integrity="sha512-xba7ZTB+CHv8PdWnPPAA89xqi2ZduMP8vWKjNo4vgu5JT9H/XwJaCSFs9jkLrHVlxUacaVjKrBudCchboK3+/A==" crossorigin=anonymous defer></script>
<script src=/js/vendor/katex/dist/katex.min.07c5862e6eea64c90e601fcaacaa0dbdb03f60dbbac68a5a5830130a00332df28001a5fa2375b739426606b441725db1af012c7e4b04b8fb222025cc0d2ac073.js integrity="sha512-B8WGLm7qZMkOYB/KrKoNvbA/YNu6xopaWDATCgAzLfKAAaX6I3W3OUJmBrRBcl2xrwEsfksEuPsiICXMDSrAcw==" crossorigin=anonymous defer></script>
<script src=/js/vendor/katex/dist/contrib/auto-render.min.bc779bab10cdc862f139e7cd6255a8f021bc483db2b7bc6d553238fb220e937dbe5cd511100d2ab764ee5d9f9092a2cdcc4e6ae109966efc18338f0b275d927d.js integrity="sha512-vHebqxDNyGLxOefNYlWo8CG8SD2yt7xtVTI4+yIOk32+XNUREA0qt2TuXZ+QkqLNzE5q4QmWbvwYM48LJ12SfQ==" crossorigin=anonymous defer></script>
<script src=/main.min.56cf146845ee56429c57a9bb74bee52540a1aa942a32506ad0d185db760f2f7a5d76f39cde824735c8b7e89f2e4453cc4da383eaa2c2a7d6a2c9dafd7061e74d.js integrity="sha512-Vs8UaEXuVkKcV6m7dL7lJUChqpQqMlBq0NGF23YPL3pddvOc3oJHNci36J8uRFPMTaOD6qLCp9aiydr9cGHnTQ==" crossorigin=anonymous defer></script>
<script src=https://memoria-framework.dev/index.min.de54b21d48900482c428ea8e41bce9f550156245a9aac91c7fa60198ec636fbcc487764aeeca99261dcfe46561c2a7cb602caf05939c197d28c5b35f3618feb5.js integrity="sha512-3lSyHUiQBILEKOqOQbzp9VAVYkWpqskcf6YBmOxjb7zEh3ZK7sqZJh3P5GVhwqfLYCyvBZOcGX0oxbNfNhj+tQ==" crossorigin=anonymous defer></script></body></html>