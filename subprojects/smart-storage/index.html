<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://memoria-framework.dev/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://memoria-framework.dev/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://memoria-framework.dev/fonts/KaTeX_Main-Regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://memoria-framework.dev/fonts/KaTeX_Math-Italic.woff2 type=font/woff2 crossorigin><link rel=stylesheet href=https://memoria-framework.dev/main.3a52b47fd32d46727919d5ee31dfaf1a70b7d47bb340b8010659a1cb153131f4f58e61dc6e8b3e488c6e105deecf67bf41ae677c2a9f4eb9df211bf4b00eb9e5.css integrity="sha512-OlK0f9MtRnJ5GdXuMd+vGnC31HuzQLgBBlmhyxUxMfT1jmHcbos+SIxuEF3uz2e/Qa5nfCqfTrnfIRv0sA655Q==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>Smart Storage - Memoria</title><meta name=description content><link rel=canonical href=https://memoria-framework.dev/subprojects/smart-storage/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Smart Storage"><meta property="og:description" content="One of the most complex problems in memory architectures is how to handle loss of power. For applications working with persistent memory, this problem is reducing to the procedure of atomic dumping of the state from volatile memory to a non-volatile memory. Even if the main memory is non-volatile, after power is restored, the entire system is in unknown state. Because power loss may occur in-between a long series of no-atomic memory updates."><meta property="og:url" content="https://memoria-framework.dev/subprojects/smart-storage/"><meta property="og:site_name" content="Memoria"><meta property="article:published_time" content="2021-10-28T02:06:54-04:00"><meta property="article:modified_time" content="2021-10-28T02:06:54-04:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content><meta name=twitter:creator content><meta name=twitter:title content="Smart Storage"><meta name=twitter:description content><meta name=twitter:card content="summary"><meta name=twitter:image:alt content="Smart Storage"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://memoria-framework.dev/#/schema/person/1","name":"Memoria","url":"https://memoria-framework.dev/","sameAs":[],"image":{"@type":"ImageObject","@id":"https://memoria-framework.dev/#/schema/image/1","url":"https://memoria-framework.dev/\u003cnil\u003e","width":null,"height":null,"caption":"Memoria"}},{"@type":"WebSite","@id":"https://memoria-framework.dev/#/schema/website/1","url":"https://memoria-framework.dev/","name":"Memoria","description":"","publisher":{"@id":"https://memoria-framework.dev/#/schema/person/1"}},{"@type":"WebPage","@id":"https://memoria-framework.dev/subprojects/smart-storage/","url":"https://memoria-framework.dev/subprojects/smart-storage/","name":"Smart Storage","description":"","isPartOf":{"@id":"https://memoria-framework.dev/#/schema/website/1"},"about":{"@id":"https://memoria-framework.dev/#/schema/person/1"},"datePublished":"2021-10-28T02:06:54CET","dateModified":"2021-10-28T02:06:54CET","breadcrumb":{"@id":"https://memoria-framework.dev/subprojects/smart-storage/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://memoria-framework.dev/subprojects/smart-storage/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://memoria-framework.dev/subprojects/smart-storage/"]}]},{"@type":"BreadcrumbList","@id":"https://memoria-framework.dev/subprojects/smart-storage/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://memoria-framework.dev/","url":"https://memoria-framework.dev/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://memoria-framework.dev/subprojects/","url":"https://memoria-framework.dev/subprojects/","name":"Subprojects"}},{"@type":"ListItem","position":3,"item":{"@id":"https://memoria-framework.dev/subprojects/smart-storage/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://memoria-framework.dev/subprojects/smart-storage/#/schema/image/2","url":null,"contentUrl":null,"caption":"Smart Storage"}]}]}</script><meta name=theme-color content="#fff"><link rel=apple-touch-icon sizes=180x180 href=https://memoria-framework.dev/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://memoria-framework.dev/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://memoria-framework.dev/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://memoria-framework.dev/site.webmanifest></head><body class="subprojects single"><div class=header-bar></div><header class="navbar navbar-expand-md navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-md-nowrap" aria-label="Main navigation"><a class="navbar-brand p-0 me-auto" href=/ aria-label=Memoria>Memoria</a>
<button class="btn btn-menu d-block d-md-none order-5" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-start border-0 py-md-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-md-none"></div><div class="offcanvas-header d-md-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=/>Memoria</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body px-4"><h3 class="h6 text-uppercase mb-3 d-md-none">Main</h3><ul class="nav flex-column flex-md-row ms-md-n3"><li class=nav-item><a class="nav-link ps-0 py-1" href=/docs/overview/introduction/>Docs</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/tutorial/quick-start>Tutorial</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/api/overview/>API</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/python/overview/>Python</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/subprojects/overview/>Subprojects</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/victor-smirnov/memoria/issues>Issues</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/victor-smirnov/memoria/discussions>Discussions</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/victor-smirnov/memoria/wiki>Releases</a></li></ul><hr class="text-black-50 my-4 d-md-none"><h3 class="h6 text-uppercase mb-3 d-md-none">Socials</h3><ul class="nav flex-column flex-md-row ms-md-auto me-md-n5 pe-md-2"><li class=nav-item><a class="nav-link ps-0 py-1" href=https://github.com/victor-smirnov/memoria><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-md-none">GitHub</small></a></li></ul></div></div></nav></header><div class="wrap container-xxl" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar d-none d-lg-block"><nav class=docs-links aria-label="Main navigation"><h3>Subprojects</h3><ul class=list-unstyled><li><a class=docs-link href=/subprojects/overview/>Subprojects Overview</a></li><li><a class="docs-link active" href=/subprojects/smart-storage/>Smart Storage</a></li><li><a class=docs-link href=/subprojects/swimmer-db/>SwimmerDB</a></li><li><a class=docs-link href=/subprojects/risc-v-core/>Accelerated RISC-V Core for Memoria</a></li><li><a class=docs-link href=/subprojects/fuse-integration/>FUSE Integration</a></li><li><a class=docs-link href=/subprojects/jenny-platform/>Jenny Metaprogramming Platform</a></li></ul></nav></div><nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=page-links><h2 class=h3>On this page</h2><nav id=TableOfContents></nav></div></nav><main class="docs-content col-lg-11 col-xl-9"><h1>Smart Storage</h1><p class=lead></p><nav class=d-xl-none aria-label="Quaternary navigation"><div class=page-links><h2 class=h3>On this page</h2><nav id=TableOfContents></nav></div></nav><p>One of the most complex problems in memory architectures is how to handle loss of power. For applications working with persistent memory, this problem is reducing to the procedure of atomic dumping of the state from volatile memory to a non-volatile memory. Even if the main memory is non-volatile, after power is restored, the entire system is in unknown state. Because power loss may occur in-between a long series of no-atomic memory updates. To successfully survive a loss of power, even NVRAM must be updated in a series of persistent atomic and recoverable steps.</p><p>Unfortunately, atomic operations are pretty expensive and hard to implement. Persistent storage block devices like HDDs and SSDs support them in a limited way: only a few consecutive blocks can be updated atomically. Filesystems and database storage engines may utilize this functionality for better resiliency, but it doesn&rsquo;t make much difference, usually. It&rsquo;s really a hard technical challenge to dump generic application&rsquo;s state from non-volatile memory to persistent memory in a fault-tolerant way.</p><p>There is some activity in this direction. Database engines support write-ahead logging (WAL), some filesystems utilize various copy-on-write (CoW) techniques. Zoned block devices (ZBD) provide WAL-like functionality at the device level. And, if it&rsquo;s supported in software (filesystems and databases), can be used to to provide much more resilient and performant storage for applications than traditional block devices.</p><p>The main idea here is to split <a href=/docs/dbfs/swmr-store>SWMRStore</a> into separate layers, and implement either its CoW block layer, or even the entire store in a storage device&rsquo;s controller. Something like ZBD, but instead on WAL it will be based on CoW.</p><p>Feature-wise, SWMRStore (pronounced &ldquo;swimmer-store&rdquo;) is somewhere between databases and filesystems. It provides linearizable multi-statement transactions (strong serializability) on top of virtually any <a href=/docs/overview/data-structure>data structure</a>, at the same time maintaining rather low level API and high IO efficiency of filesystems. So, applications may have best of both worlds.</p><p>Internally, SWMRStore is pretty similar to <a href=http://www.lmdb.tech/doc/>LMDB</a>, except the following things:</p><ol><li>SWMRStore supports more block sizes: 4K, 8K, 16K, &mldr; 1M.</li><li>SWMRStore supports checkpoints, so applications can opt-in into relaxed durability gaining some speed.</li><li>SWMRStore provides history of transactions and branches (all branches are still single-writer though).</li><li>SWMRStore does not depend on memory mapping and may operate on top of any block device using high-performance IO interfaces like IOCP/Linux AIO/<a href=https://en.wikipedia.org/wiki/Io_uring>io_uring</a>.</li></ol><p>LMDB is build on top of memory-mapping, with rather simple data model (key/value data only), it&rsquo;s really lightning-fast because of that, and has a small code footprint. SWMRStore is not nearly as lightweight as LMDB (because of tons of additional features and better scalability), but it&rsquo;s still the same provably-correct wait-free <a href=https://en.wikipedia.org/wiki/Multiversion_concurrency_control>MVCC</a>, because of Copy-on-Wright scheme.</p><p>It&rsquo;s not that everything is good in single-writer/multiple-readers (SWMR) CoW kingdom. This storage management scheme has two main limitations:</p><ul><li><strong>Only single read-write transaction at a time is possible</strong>. This is a fundamental limitation that can be only slightly relaxed in some cases. Concurrent writers, if they are required, have to be somehow dispatched using the single writer transaction, sacrificing isolation and making rollbacks much more expensive.</li><li><strong>CoW requires ether some garbage collection (GC) or reference counting (RC) to reclaim the space</strong>. GC is seriously limiting the scalability of CoW-based storage, and RC is hard to implement in a copy-on-write way efficiently. So, RC itself is usually not transactional.</li></ul><p>SWMRStore is using RC-based space reclamation scheme, and in case of unexpected power loss, partial storage scan (typically, 1-10% of <em>allocated</em> blocks) is required to rebuild block counters <em>before</em> the storage is writable again (counters are not needed for reading). Though it&rsquo;s expected that recovery time is rather small in absolute numbers (like, a few seconds), but, nevertheless, recovery has $O(M)$ time complexity, where $M$ is the data volume. In case when it&rsquo;s not acceptable, GC is an option.</p><p>Another limitation is that block reference counters are operated in RAM, so for RC-based CoW we do need a RAM buffer of the size, linearly proportional to the size of data.</p><p>But, given that those limitations are not vital for an application, SWMR CoW can theoretically achieve very high transaction rates, up to millions TPS per consistency domain (usually a database or a filesystem, or a shard). This is because CoW is intrinsically wait-free in the data path, and there is only one (no transaction history) or two locks (with transaction history and branches) in the store, which, technically, can be implemented directly in hardware for ultimate efficiency. Other than those one or two locks, readers and writers do not interact with each other in any way when accessing the data.</p><p>Another important property of SWMR CoW is that live data is never over-written between transactions. In other words, if some physical block $B$ was written in transaction $T_1$, it will never be overwritten in transaction $T_i, i>1$, unless it&rsquo;s freed in some $T_j, j > 1, j &lt; i$. Notable exceptions are superblocks, but there is a fixed number of them, so they can be handled specially. Blocks within a writable transaction can be over-written (updated), but both reader and writer transactions in Memoria are intrinsically single-threaded. So, such updates are naturally serialized anyway.</p><p>So, in SWMRStore:</p><ul><li>concurrent multi-threaded access is only possible to immutable (read-only) blocks;</li><li>mutable blocks are only accessed sequentially;</li><li>and there is a clear transactionally-aligned block life-cycle (allocate-update-free).</li></ul><p><strong>Specifics of this block access pattern can be used for both simplifying the data stack and making it more resilient and fault-tolerant, comparing with traditional block devices, which are designed for the more general case: concurrent access to the mutable data</strong>.</p><p>For example, NAND flash SSDs have pretty complex controller inside, implementing specific copy-on-write techniques over NAND flash chips. This is because NAND can&rsquo;t naturally handle block-sized data updates. Having CoW over NAND, then Block Device API over this CoW, then SWMRStore over this BD API looks like adding a lot of unnecessary complexity into the data stack. It&rsquo;s logical to allow SWMRStore to manage NAND flash directly, <strong>skipping generic blocks device API emulation completely</strong>. Technically, SWMRStore has it&rsquo;s own block ID translation layer, that can be extended to handle flash directly. What it the most important, manufacturers of such SWMRStore-based block devices can deeply optimize everything together, keeping critical inventions in secret by not exposing them publicly via device API.</p><div class="docs-navigation d-flex justify-content-between"><a href=/subprojects/overview/><div class="card my-1"><div class="card-body py-2">&larr; Subprojects Overview</div></div></a><a class=ms-auto href=/subprojects/swimmer-db/><div class="card my-1"><div class="card-body py-2">SwimmerDB &rarr;</div></div></a></div></main></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Powered by <a href=https://www.github.com/>Github</a>, <a href=https://gohugo.io/>Hugo</a>, and <a href=https://getdoks.org/>Doks</a></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline><li class=list-inline-item><a href=/privacy-policy/>Privacy</a></li></ul></div></div></div></footer><script src=/js/bootstrap.min.73ca27033146a505b6a0f66b79d99f613a18e778bc9606fd223476d0ebf0fc10508b0d4f5c448b0a946fa1d71fbeffaae9732adc0c2890e61c449217fd6ee1c0.js integrity="sha512-c8onAzFGpQW2oPZredmfYToY53i8lgb9IjR20Ovw/BBQiw1PXESLCpRvodcfvv+q6XMq3AwokOYcRJIX/W7hwA==" crossorigin=anonymous defer></script>
<script src=/js/highlight.min.20b134e1144736c37382377dc01a9a460e52977eddf8b128d70c597f1073660effc532a82d05184541720a95a88efcda25a0528b0f47d23a04f4e3bd997122eb.js integrity="sha512-ILE04RRHNsNzgjd9wBqaRg5Sl37d+LEo1wxZfxBzZg7/xTKoLQUYRUFyCpWojvzaJaBSiw9H0joE9OO9mXEi6w==" crossorigin=anonymous defer></script>
<script src=/js/vendor/katex/dist/katex.min.849bcb0a26d9f709f5e2355f5188d1c21e07bb04544918a1c2a6d290dc2ebcb9b787ba92911f609242c898b7ce8009c541be9153a357e673818164f829d917fe.js integrity="sha512-hJvLCibZ9wn14jVfUYjRwh4HuwRUSRihwqbSkNwuvLm3h7qSkR9gkkLImLfOgAnFQb6RU6NX5nOBgWT4KdkX/g==" crossorigin=anonymous defer></script>
<script src=/js/vendor/katex/dist/contrib/auto-render.min.916823ec103cf367b71e28a6f01513cb9c3ac6708ccb5229402ec46b8e30a8b25003db694df35d80e9dd666a371f327c6152790617b6256390c164109a90bd4c.js integrity="sha512-kWgj7BA882e3Hiim8BUTy5w6xnCMy1IpQC7Ea44wqLJQA9tpTfNdgOndZmo3HzJ8YVJ5Bhe2JWOQwWQQmpC9TA==" crossorigin=anonymous defer></script>
<script src=/main.min.56cf146845ee56429c57a9bb74bee52540a1aa942a32506ad0d185db760f2f7a5d76f39cde824735c8b7e89f2e4453cc4da383eaa2c2a7d6a2c9dafd7061e74d.js integrity="sha512-Vs8UaEXuVkKcV6m7dL7lJUChqpQqMlBq0NGF23YPL3pddvOc3oJHNci36J8uRFPMTaOD6qLCp9aiydr9cGHnTQ==" crossorigin=anonymous defer></script></body></html>